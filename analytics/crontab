SHELL=/bin/sh

# List is at https://groups.google.com/a/khanacademy.org/group/analytics-admin
# NOTE: make sure the google group is set up to have root@khanacademy.org
#       as a member, or this mail will bounce!
MAILTO=analytics-admin+crontab@khanacademy.org

# This is a mini-script to create and return a directory-name under
# kalogs for the current date.  This is used to redirect output of
# cronjobs to a logfile.  As an example:
#    `eval $LOGFILE foo`
# expands to
#    ~/kalogs/foo/foo.2012-12-25.log
# You can also specify other arguments, which are passed to date:
#    `eval $LOGFILE foo --date=yesterday`
# expands to
#    ~/kalogs/foo/foo.2012-12-24.log
# (The redundant foo's are in case the logfiles get moved around,
# perhaps by accident; we can still tell where they came from.)
#
# This implementation uses a trick: the first argument after the
# <<sh -c ''>> is taken as $0, while $@ expands to "$1" "$2" "$3" ...
# but skips $0, which is exactly what we want in this case.
LOGFILE=bash -c 'mkdir -p ~/kalogs/$0; echo ~/kalogs/$0/$0.$(date "$@" +\%Y-\%m-\%d).log'


# Fetch topic tree and versions every day
00 2 * * * bash --login -c '~/analytics/src/fetch_topic_tree.py' > `eval $LOGFILE fetch_topic_tree --date=yesterday` 2>&1

# Fetch webpagetest performance data every day.  We try to do it
# during the peak part of the day to get 'worst-case' numbers.
# We'll imagine that's around noon EDT, which is 6pm UTC.
# The 'echo' will get sent as mail, if the cronjob has a non-zero exit code.
00 18 * * * bash --login -c 'cd ~/analytics/src/webpagetest && ./run_webpagetest.py' > `eval $LOGFILE webpagetest --date=today` 2>&1 || echo "webpagetest run failed; see `eval $LOGFILE webpagetest --date=today`"

# Fetch GAE usage reports every day. Reports are generated at about 1430 PST
# which is 2130 UTC, and we allow for a bit of wiggle room.
00 22 * * * bash --login -c '~/analytics/src/gae_dashboard/fetch_usage.sh' > `eval $LOGFILE gae_dashboard_usage --date=yesterday` 2>&1

# Load the topic_attempts Hive table, which requires GAE Hive tables to have
# loaded (from load_emr_daily.sh)
# TODO(david): This should be a generic python script to run any arbitrary hive
#     script with # instances, etc. configurable by cmd line args
# TODO(david): Ensure this runs after completion of the load_emr_daily job.
04 5 * * * bash --login -c '~/analytics/map_reduce/shell/load_topic_attempts.sh' > `eval $LOGFILE load_topic_attempts --date=yesterday` 2>&1

# Fetch raw datastore entities every hour.
05 * * * * bash --login -c '~/analytics/src/gae_download.py -c ~/analytics/cfg/gae_download.json' >> `eval $LOGFILE gae_download` 2>&1

# Fetch GAE admin UI stats.
*/5 * * * * bash --login -c '~/analytics/src/gae_dashboard/fetch_stats.sh' >> `eval $LOGFILE gae_dashboard_stats` 2>&1

# Fetch logs every hour.  We fetch the previous hour by default, so
# start a few minutes after the hour to give those logs time to flush.
# The 'echo' will get sent as mail, if the cronjob fails or the
# timeout triggers.
# TODO(csilvers): have log-to-logfile occur here, not in fetch_logs.sh
03 * * * * /usr/bin/timeout 120m ~/analytics/src/fetch_logs.sh || echo "analytics: fetch-logs failed with error $? [redo it manually?]"

# Fetch appengine statistics (memcache, etc) every 10 minutes.
*/10 * * * * bash --login -c 'curl -s "http://www.khanacademy.org/stats/memcache?output=txt"' >> `eval $LOGFILE appengine_stats` 2>&1

# Upload GAE data to EMR daily; Run daily reporting jobs
03 2 * * * bash --login -c '~/analytics/map_reduce/load_emr_daily.sh' > `eval $LOGFILE load_emr --date=yesterday` 2>&1

# Weekly reporting jobs
00 12  * * 0 bash --login -c '~/analytics/src/run_report.sh week' >> `eval $LOGFILE weekly_report` 2>&1

# Monthly reporting jobs
00 09 1 * * bash --login -c '~/analytics/src/run_report.sh month' >> `eval $LOGFILE monthly_report` 2>&1

